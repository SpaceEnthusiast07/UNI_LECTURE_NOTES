[Slides](https://ele.exeter.ac.uk/pluginfile.php/5587348/mod_resource/content/1/Lecture%2010%20Updated.pdf)


##### Contents
 - [[#Branch Prediction]]
 - [[#Types of Branch Prediction]]
 - [[#Example 2-bit Branch Predictor]]
 - [[#Speculative Execution]]
 - [[#In-order vs. Out-of-order Execution]]
 - [[#Principle of Locality]]
 - [[#90-10 Rule of Thumb]]
 - [[#Amdahl's Law]]


##### Branch Prediction
 - Branch instructions control the flow of a program.
 - When a branch is encountered, the program needs to decide whether to jump to another part of the code or continue with the immediate next instruction.


##### Types of Branch Prediction
 - **Static Branch Prediction**
	 - Make a fixed prediction based on a simple rule, without considering runtime behaviour.
	 - Common techniques: always taken, always not taken, backward branch (loop).
 - **Dynamic Branch Prediction**
	 - Adjust predictions based on runtime behaviour.
 - **Hybrid Branch Prediction**
	 - ...


##### Example: 2-bit Branch Predictor
![[Pasted image 20260213105138.png]]
 - The above diagram is a **State Machine**.
 - The red writing on the left is an example scenario:
	 - Initial state ...


##### Speculative Execution
 - ...


##### In-order vs. Out-of-order Execution
 - **In-order**
	 - Instructions are executed in the exact sequence they appear in the program.
	 - ...
 - **Out-of-order**
	 - ...


##### Principle of Locality
 - Locality is a fundamental concept in computer architecture that states program tend to access a small, localised portion of memory repeatedly over short periods of time.
 - There are two main types:
	 - **Temporal Locality**
		 - If a memory location is accessed, it is likely to be *accessed again soon*.
		 - Example: A loop iterating over an array repeatedly accesses the same variables.
		 - ...
	 - **Spatial Locality**
		 - ...


##### 90-10 Rule of Thumb
 - The idea is that the program spends ~90% of execution time in just ~10% of the code.
 - The exact percentages can change, but the idea is the same.
 - Not all parts of a program are equally important for performance.
 - Key Takeaways:
	 - Focus on optimising the 10% of code, rather than the optimisation ...
	 - ...


##### Amdahl's Law
 - **Amdahl's Law** states that the performance improvements to be gained from using some faster mode of execution (or parallelism) is limited by the fraction of time that the faster mode can be used!
 - Formula to calculate the speedup: ![[Pasted image 20260213161125.png]]
 - The overall speedup is comprised of two parts:
	 - **Enhancement fraction**
		 - The fraction of the computation time that can be converted to take advantage of enhancement.
		 - Example: if a task takes 60 seconds, but 20 seconds can benefit from an enhancement, then $\text{Fraction}_\text{Enhanced} = \frac{20}{60}$.
		 - This fraction is always $\leq1$
	 -  **Speedup Fraction**
		 - The improvement gained by the enhanced execution mode.
		 - I.e. how much faster the task would run if the enhanced mode were used for the entire program.
		 - Fraction = time of original over time of enhanced.
		 - Example:
			 - Say a task took 10 seconds, but with enhancement it takes 2 seconds.
			 - Then, $\text{Speedup}_{\text{Enhanced}} = \frac{10}{2} = 5\text{x improvement}$.
			 - This speedup fraction will always be $\geq1$, because there could be no improvement possible.
 - Overall speed up formula:
$$\text{Speedup}_{\text{Overall}} = \frac{\text{Execution Time}_{\text{old}}}{\text{Execution Time}_{\text{new}}} = \frac{1}{(1-\text{Fraction}_{\text{Enhanced}})+\frac{\text{Fraction}_{\text{Enhanced}}}{\text{Speedup}_{\text{Enhanced}}}}$$











