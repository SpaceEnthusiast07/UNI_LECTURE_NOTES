[Slides](https://ele.exeter.ac.uk/pluginfile.php/5531346/mod_resource/content/6/ECM1413-Computers%20and%20the%20Internet-Lecture%207%20-%20Computing%20Architectures%20-%20Evolution%20and%20Brief%20History.pdf)


##### Contents
 - [[#From High Level Language to Hardware]]
 - [[#History and Performance Trends]]
 - [[#Classes of Computers]]
 - [[#Flynn's Taxonomy]]
 - 


##### From High Level Language to Hardware
**Application Level**
 - Programs are written in high-level languages (like C) using *millions of lines of complex instructions*.
 **Translation Process**
 - A **Compiler** *converts this high-level* code into **Assembly Language** specific to an architecture (e.g. MIPS).
 **Hardware Execution**
 - Finally, an **Assembler** *translates assembly* into **Binary Machine Language** (1s and 0s) that the *hardware can directly process*.


##### History and Performance Trends
**Evolutionary Eras**
 - Computers have progressed through phases of *Electromechanical Relays*, *Vacuum Tubes*, *Transistors*, and *Integrated Circuits*.
**Performance Drivers**
 - **Pre 1980s**: Growth was *technology-driven*, averaging 22% performance increaser per year.
 - **1986-2003**: The introduction of *RISC* architectures caused a *performance explosion*, doubling performance every 1.5 years (52% annually).
 - **Post 2003**: Performance growth slowed die to the "Power Wall" (end of Dennard scaling) and limits in instruction-level parallelism, forcing a shift to multicore processors.
 - **Current State**: Since 2015, with the end of Moore's Law, annual improvement has dropped to approx. 3.5%.


##### Classes of Computers
Computers are *categorised* by their *function and the specific constraints* they must meet:
 - **Personal Mobile Devices (PMDs)**
	 - Focus on *cost*, *energy efficiency*, and *size* (e.g. smartphones, tablets, laptops).
 - **Desktop Computers**
	 - Prioritise the *trade-off* between *cost and performance*.
 - **Servers**
	 - Emphasise *availability* (24/7 execution), *scalability* (add more power), and *throughput* (amount of work per unit time).
 - **Clusters/Warehouse Scale**
	 - *Massive collection of servers* for "*Software as a Service*" (SaaS), where power and price-to-performance ratio are critical.
 - **Embedded computers**
	 - Found in everything from microwaves to aerospace systems, focusing on *reliability* and *application-specific performance*.


##### Flynn's Taxonomy
*Michael Flynn's* 1966 *classification system* remains a standard for describing how computers handle *instructions and data streams*:
 - **SISD (Single Instruction, Single Data)**
	 - Standard sequential uniprocessor.
 - **SIMD (Single Instruction, Multiple Data)**
	 - One instruction operates on many data points simultaneously, exploiting data-level parallelism.
	 - Like a GPU, e.g. perform addition on multiple pieces of data simultaneously.
 - **MISD (Multiple Instruction, Single Data)**
	 - Primarily theoretical, no commercial versions exist.
	 - Perform 2 or more different instructions on the same data simultaneously.
	 - The resulting value depends on which instruction finishes last.
	 - Therefore, the result may not always be what is desired.
 - **MIMD (Multiple Instruction, Multiple Data)**
	 - Each processor has its own instructions and data, offering high flexibility for task-level parallelism.


##### RISC vs. CISC Architectures
 - **CISC (Complex Instruction Set Computing)**
	 - Aims to *reduce* the number of *instructions per program* by making *each instruction more complex*, which in turn *increases* the number of CPU *clock cycles per instruction*.
	 - Since each instruction is more complex, they naturally *require more memory*.
 - **RISC (Reduced Instruction Set Computing)**
	 - Aims to *reduce* the *clock cycles per instruction* (ideally to one) by using a *simpler, smaller instruction set*, even if it means *more instructions* are needed *per program*.
	 - Since each instruction is simpler and the instruction set is smaller, *less memory is required*.


##### Key Characteristics of RISC
**Fixed Instruction Length**
 - Usually 32 bits (one word), making decoding faster and simpler.
**Single Cycle Execution**
 - Aim to execute every instruction in one CPU clock cycle.
**Load/Store Architecture**
 - Memory is only accessed via specific load and store instructions; all other operations happen with registers.
**Large Register Set**
 - Contain a larger number of general purpose registers, which minimises slow memory access by keeping more data within the CPU.
**Efficient Pipelining**
 - Because *instructions* are *uniform* (of the same length), they can be *processed* in *overlapping stages* to increase throughput (no of ops per unit time).
**Examples**
 - *ARM* - mobile/embedded
 - *MIPS* - networking/consoles
 - *SPARC* - servers


